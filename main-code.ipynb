{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importando as bibliotecas utilizadas ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ANACONDA\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import gensim\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicializando o DataFrame da matriz dos conhecimentos, \n",
    "utilizando a função 'fillna' para consertar as células mescladas,\n",
    "lendo a partir da linha 4\n",
    "e lendo até a coluna 9 (excluso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "crea_df = pd.read_excel(\"Matriz_do_Conhecimento.xls\", skiprows=4).iloc[:, :9].fillna(method=\"ffill\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Corrigindo valores que foram incorretamente preenchido pelo método fillna(\"ffill\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "crea_df = crea_df.replace({\"TÓPICOS\": np.NaN, \"Nº DE ORDEM DOS TÓPICOS\": np.NaN})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando o Dataframe com o pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('crea_df_pickle.txt', 'wb') as f:\n",
    "    pickle.dump(crea_df, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abrindo o dataFrame em formato Binário e Imprimindo o DataFrame para fins de visualização:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nº DE ORDEM DO SETOR</th>\n",
       "      <th>SETOR</th>\n",
       "      <th>Nº DE ORDEM DO SUB-SETOR</th>\n",
       "      <th>SUB-SETOR</th>\n",
       "      <th>Nº DE ORDEM DOS TÓPICOS</th>\n",
       "      <th>TÓPICOS</th>\n",
       "      <th>TIPO</th>\n",
       "      <th>ÁREA DE CONHECIMENTO</th>\n",
       "      <th>CONTEÚDO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22400</th>\n",
       "      <td>1.16</td>\n",
       "      <td>Controle e Automação</td>\n",
       "      <td>1.16.01.00</td>\n",
       "      <td>Sistemas Discretos e Contínuos</td>\n",
       "      <td>1.15.03.04</td>\n",
       "      <td>Biomecânicos</td>\n",
       "      <td>Básico</td>\n",
       "      <td>Física</td>\n",
       "      <td>Medidas físicas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22401</th>\n",
       "      <td>1.16</td>\n",
       "      <td>Controle e Automação</td>\n",
       "      <td>1.16.01.00</td>\n",
       "      <td>Sistemas Discretos e Contínuos</td>\n",
       "      <td>1.15.03.04</td>\n",
       "      <td>Biomecânicos</td>\n",
       "      <td>Básico</td>\n",
       "      <td>Física</td>\n",
       "      <td>Mecânica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22402</th>\n",
       "      <td>1.16</td>\n",
       "      <td>Controle e Automação</td>\n",
       "      <td>1.16.01.00</td>\n",
       "      <td>Sistemas Discretos e Contínuos</td>\n",
       "      <td>1.15.03.04</td>\n",
       "      <td>Biomecânicos</td>\n",
       "      <td>Básico</td>\n",
       "      <td>Física</td>\n",
       "      <td>Eletromagnetismo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22403</th>\n",
       "      <td>1.16</td>\n",
       "      <td>Controle e Automação</td>\n",
       "      <td>1.16.01.00</td>\n",
       "      <td>Sistemas Discretos e Contínuos</td>\n",
       "      <td>1.15.03.04</td>\n",
       "      <td>Biomecânicos</td>\n",
       "      <td>Básico</td>\n",
       "      <td>Física</td>\n",
       "      <td>Gravitação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22404</th>\n",
       "      <td>1.16</td>\n",
       "      <td>Controle e Automação</td>\n",
       "      <td>1.16.01.00</td>\n",
       "      <td>Sistemas Discretos e Contínuos</td>\n",
       "      <td>1.15.03.04</td>\n",
       "      <td>Biomecânicos</td>\n",
       "      <td>Básico</td>\n",
       "      <td>Física</td>\n",
       "      <td>Termodinâmica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24606</th>\n",
       "      <td>1.16</td>\n",
       "      <td>Controle e Automação</td>\n",
       "      <td>1.16.09.00</td>\n",
       "      <td>Nano-eletromecânica</td>\n",
       "      <td>1.16.07.02</td>\n",
       "      <td>Máquinas de Operação Autônoma</td>\n",
       "      <td>Profissionalizante</td>\n",
       "      <td>Materiais Elétricos</td>\n",
       "      <td>Materiais Magnéticos e Ferromagnéticos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24607</th>\n",
       "      <td>1.16</td>\n",
       "      <td>Controle e Automação</td>\n",
       "      <td>1.16.09.00</td>\n",
       "      <td>Nano-eletromecânica</td>\n",
       "      <td>1.16.07.02</td>\n",
       "      <td>Máquinas de Operação Autônoma</td>\n",
       "      <td>Profissionalizante</td>\n",
       "      <td>Materiais Elétricos</td>\n",
       "      <td>Ligas Metálicas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24608</th>\n",
       "      <td>1.16</td>\n",
       "      <td>Controle e Automação</td>\n",
       "      <td>1.16.09.00</td>\n",
       "      <td>Nano-eletromecânica</td>\n",
       "      <td>1.16.07.02</td>\n",
       "      <td>Máquinas de Operação Autônoma</td>\n",
       "      <td>Profissionalizante</td>\n",
       "      <td>Materiais Elétricos</td>\n",
       "      <td>Modelos Atômicos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24609</th>\n",
       "      <td>1.16</td>\n",
       "      <td>Controle e Automação</td>\n",
       "      <td>1.16.09.00</td>\n",
       "      <td>Nano-eletromecânica</td>\n",
       "      <td>1.16.07.02</td>\n",
       "      <td>Máquinas de Operação Autônoma</td>\n",
       "      <td>Profissionalizante</td>\n",
       "      <td>Materiais Elétricos</td>\n",
       "      <td>Polarização e Perdas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24610</th>\n",
       "      <td>1.16</td>\n",
       "      <td>Controle e Automação</td>\n",
       "      <td>1.16.09.00</td>\n",
       "      <td>Nano-eletromecânica</td>\n",
       "      <td>1.16.07.02</td>\n",
       "      <td>Máquinas de Operação Autônoma</td>\n",
       "      <td>Profissionalizante</td>\n",
       "      <td>Materiais Elétricos</td>\n",
       "      <td>Mecanismos de Condução e Ruptura em Dielétricos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2211 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Nº DE ORDEM DO SETOR                 SETOR Nº DE ORDEM DO SUB-SETOR  \\\n",
       "22400                 1.16  Controle e Automação               1.16.01.00   \n",
       "22401                 1.16  Controle e Automação               1.16.01.00   \n",
       "22402                 1.16  Controle e Automação               1.16.01.00   \n",
       "22403                 1.16  Controle e Automação               1.16.01.00   \n",
       "22404                 1.16  Controle e Automação               1.16.01.00   \n",
       "...                    ...                   ...                      ...   \n",
       "24606                 1.16  Controle e Automação               1.16.09.00   \n",
       "24607                 1.16  Controle e Automação               1.16.09.00   \n",
       "24608                 1.16  Controle e Automação               1.16.09.00   \n",
       "24609                 1.16  Controle e Automação               1.16.09.00   \n",
       "24610                 1.16  Controle e Automação               1.16.09.00   \n",
       "\n",
       "                            SUB-SETOR Nº DE ORDEM DOS TÓPICOS  \\\n",
       "22400  Sistemas Discretos e Contínuos              1.15.03.04   \n",
       "22401  Sistemas Discretos e Contínuos              1.15.03.04   \n",
       "22402  Sistemas Discretos e Contínuos              1.15.03.04   \n",
       "22403  Sistemas Discretos e Contínuos              1.15.03.04   \n",
       "22404  Sistemas Discretos e Contínuos              1.15.03.04   \n",
       "...                               ...                     ...   \n",
       "24606             Nano-eletromecânica              1.16.07.02   \n",
       "24607             Nano-eletromecânica              1.16.07.02   \n",
       "24608             Nano-eletromecânica              1.16.07.02   \n",
       "24609             Nano-eletromecânica              1.16.07.02   \n",
       "24610             Nano-eletromecânica              1.16.07.02   \n",
       "\n",
       "                             TÓPICOS                TIPO ÁREA DE CONHECIMENTO  \\\n",
       "22400                   Biomecânicos              Básico               Física   \n",
       "22401                   Biomecânicos              Básico               Física   \n",
       "22402                   Biomecânicos              Básico               Física   \n",
       "22403                   Biomecânicos              Básico               Física   \n",
       "22404                   Biomecânicos              Básico               Física   \n",
       "...                              ...                 ...                  ...   \n",
       "24606  Máquinas de Operação Autônoma  Profissionalizante  Materiais Elétricos   \n",
       "24607  Máquinas de Operação Autônoma  Profissionalizante  Materiais Elétricos   \n",
       "24608  Máquinas de Operação Autônoma  Profissionalizante  Materiais Elétricos   \n",
       "24609  Máquinas de Operação Autônoma  Profissionalizante  Materiais Elétricos   \n",
       "24610  Máquinas de Operação Autônoma  Profissionalizante  Materiais Elétricos   \n",
       "\n",
       "                                              CONTEÚDO  \n",
       "22400                                  Medidas físicas  \n",
       "22401                                        Mecânica   \n",
       "22402                                 Eletromagnetismo  \n",
       "22403                                       Gravitação  \n",
       "22404                                    Termodinâmica  \n",
       "...                                                ...  \n",
       "24606           Materiais Magnéticos e Ferromagnéticos  \n",
       "24607                                  Ligas Metálicas  \n",
       "24608                                 Modelos Atômicos  \n",
       "24609                             Polarização e Perdas  \n",
       "24610  Mecanismos de Condução e Ruptura em Dielétricos  \n",
       "\n",
       "[2211 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('crea_df_pickle.txt', 'rb') as f:\n",
    "    crea_df = pickle.load(f)\n",
    "\n",
    "# * subseção de Construção de Edificações\n",
    "subsection1_df = crea_df[ crea_df['SUB-SETOR' ] == 'Construção de Edificações']\n",
    "\n",
    "mechatronics_df = crea_df[ crea_df['SETOR'] == 'Controle e Automação']\n",
    "\n",
    "# mechatronics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importando as matérias que foram manualmente obtidas e salvas em um arquivo json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects_df = pd.read_json(\"MechatronicsEngeneeringSubjects.json\")\n",
    "\n",
    "# subjects_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando uma função de pre-processamento de texto. Retira ruidos(cleaning) -> tokeniza-lemmatiza -> depois retira stopwords;\n",
    "\n",
    "Recebe um texto no formato de string e retorna uma lista de strings com as palavras do documento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "nlp = spacy.load('pt_core_news_lg')\n",
    "\n",
    "# TODO: find out if it is definately impossible to disable PoS tags in nlp model; alternative: convert all verbs to noun using wordnet and .pos from spacy?\n",
    "# TODO: implementar o tagger utilizando o seguinte banco de dados: https://www.nltk.org/howto/portuguese_en.html#accessing-the-macmorpho-tagged-corpus\n",
    "# tagger = nlp.get_pipe(\"tagger\")\n",
    "# doc = nlp(\"eletromagnetismo serie\")\n",
    "# print(tagger.model.predict([doc])[0][1])\n",
    "# print(tagger.labels)\n",
    "\n",
    "# * adding custom texts that dont represent real words\n",
    "noises_list = [\"i\", \"ii\", \"iii\", \"iv\", \"v\", \"vi\", \"vii\", \"viii\", \"ix\", \"x\", \"xi\"]\n",
    "\n",
    "stopWords_list = stopwords.words(\"portuguese\")\n",
    "\n",
    "# * adding custom words to StopWords list\n",
    "stopWords_list += [\n",
    "    'referente',\n",
    "    'seguinte',\n",
    "    'etc',\n",
    "    'ª',\n",
    "    'tal',\n",
    "    'um', \n",
    "    'dois',\n",
    "    'tres',\n",
    "    'vs',\n",
    "    'aula',\n",
    "    'tal',\n",
    "]\n",
    "\n",
    "# * preprocessing stopwords to correct format\n",
    "stopWords_list = gensim.utils.simple_preprocess(\" \".join(stopWords_list), deacc=True, min_len=1, max_len=40)\n",
    "\n",
    "# print(stopWords_list)\n",
    "\n",
    "# * manual intervention, changing final lemmas\n",
    "intervention_dict = {\n",
    "    \"campar\": \"campo\",\n",
    "    \"seriar\":\"serie\",\n",
    "    \"eletromagnetico\":\"eletromagnetismo\",\n",
    "}\n",
    "\n",
    "def preprocess(text):\n",
    "    # * importing stopwords from nltk and spacy pipeline\n",
    "    global nlp\n",
    "    global stopWords_list\n",
    "    global noises_list\n",
    "    global intervention_dict\n",
    "\n",
    "    # * preprocessing text with gensim.simple_preprocess, eliminating noises: lowercase, tokenized, no symbols, no numbers, no accents marks(normatize)\n",
    "    text_list = gensim.utils.simple_preprocess(text, deacc=True, min_len=1, max_len=40)\n",
    "\n",
    "    # * recombining tokens to a string type object and removing remaining noises\n",
    "    text_str = \" \".join([word for word in text_list if word not in noises_list])\n",
    "\n",
    "    # * preprocessing with spacy, retokenizing -> tagging parts of speech (PoS) -> parsing (assigning dependencies between words) -> lemmatizing\n",
    "    text_doc = nlp(text_str)\n",
    "\n",
    "    # * re-tokenization, removing stopwords and lemmatizing\n",
    "    lemmatized_text_list = [token.lemma_ for token in text_doc if token.text not in stopWords_list]\n",
    "\n",
    "    # * manual intervention conversion of lemmas and removing 1 letter stopwords\n",
    "    output = []\n",
    "    for token in lemmatized_text_list:\n",
    "        if len(token) <= 1:\n",
    "            continue\n",
    "        if token in intervention_dict:\n",
    "            output.append(intervention_dict[token])\n",
    "        else:\n",
    "            output.append(token)\n",
    "            \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-processando as matérias com Stopwords do NLTK e função do Gensim. E adicionando uma nova columa ao Dataframe que consiste em todo o texto da matéria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_list = []\n",
    "\n",
    "for i, row in subjects_df.iterrows():\n",
    "\n",
    "    # * reading values of each subject (row)\n",
    "    subject_id = row[\"codigo\"]\n",
    "    name = row[\"nome\"]\n",
    "    syllabus = row[\"ementa\"]\n",
    "    content = row[\"conteudo\"]\n",
    "\n",
    "    # * combining them to create the subject document\n",
    "    text = name + ' ' + syllabus + ' ' + content\n",
    "    \n",
    "    # * preprocessing\n",
    "    preProcessedText = preprocess(text)\n",
    "    documents_list.append(preProcessedText)\n",
    "\n",
    "# print(documents_list)\n",
    "\n",
    "documents_series = pd.Series(documents_list, name=\"documento\")\n",
    "\n",
    "documents_df = pd.concat([subjects_df, documents_series], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando o Dataframe das matérias,  reabrindo-o e imprimindo o DataFrame para fins de visualização:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('documents_df.txt', 'wb') as f:\n",
    "    pickle.dump(documents_df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('documents_df.txt', 'rb') as f:\n",
    "    documents_df = pickle.load(f)\n",
    "\n",
    "# documents_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando a coluna de documentos para tornar legível e facilitar a busca, assim podendo conferir se os lemmas estão satisfatórios e se condizem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"debbuging_docs.json\", \"w+\") as f:\n",
    "    json.dump(documents_df['documento'].to_dict(), f, indent=4, ensure_ascii=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "construindo o Corpus, vetorizando os documentos com o bag-of-words do gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora\n",
    "\n",
    "lemmatizedData = documents_df[\"documento\"].tolist()\n",
    "\n",
    "# * gensim dictionary object, which will track each word to its respective id\n",
    "id2wordDict = corpora.Dictionary(lemmatizedData)\n",
    "\n",
    "# * gensim doc2bow method to map each word to a integer id and its respective frequency\n",
    "corpus = [id2wordDict.doc2bow(text) for text in lemmatizedData]\n",
    "\n",
    "# * list of list of tuples (id of a word, frequency)\n",
    "# corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando tf-idf do gensim para descobrir as palavras mais importantes e dar mais pesos a elas;\n",
    "\n",
    "tupla(int, int) -> tupla(int, float)\n",
    "\n",
    "td-idf(term_i, document_j) = freq(i,j) * log2 ( inverse_document_frequency(i) )\n",
    "\n",
    "freq(i, j) = total occurances of i in j / total words in j\n",
    "\n",
    "inverse_document_frequency(i) = total documents / documents that have at least one occurance of i \n",
    "\n",
    "O parâmetro id2word recebe o dicionário que mapeia as palavras com os respectivos IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_model = gensim.models.TfidfModel(corpus, id2word=id2wordDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSI, pega a matriz do corpus e a decompõe utilizando o SVD. Das três matrizes criadas, utiliza-se apenas o right singular vectors que representa a relação entre os tópicos latentes com as palavras.\n",
    "\n",
    "O parâmetro id2word recebe o dicionário que mapeia as palavras com os respectivos IDs. E o parâmetro power_iters define o número de iterações para treinamento do modelo, e, portanto, quanto maior o valor, mais acurado e mais devagar vai ser o treino modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsi_model = gensim.models.LsiModel(tfidf_model[corpus], id2word=id2wordDict, num_topics=100, power_iters=100)\n",
    "\n",
    "# lsi_model.print_topics(num_topics=56)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "left singular vector -> term-to-topic matrix (não será utilizado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1869, 56)\n"
     ]
    }
   ],
   "source": [
    "# * U Matrix\n",
    "print(np.shape(lsi_model.projection.u))\n",
    "\n",
    "# lsi_model.projection.u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "singular values -> \"impacto\" (abrangência?) de cada tópico -> \"feature importance\"\n",
    "\n",
    "Pode-se escolher um valor de corte para reduzir o valor do parametro num_topics, aumentando, assim, o desempenho de tempo. O número de tópicos latentes não tem como ser maior que o numero de documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "número de documentos/ementas/matérias: 57\n",
      "topicos latentes encontrados com um 'impacto alto': 56\n"
     ]
    }
   ],
   "source": [
    "print(\"número de documentos/ementas/matérias:\", len(subjects_df))\n",
    "print(\"topicos latentes encontrados com um \\'impacto alto\\':\", len(lsi_model.projection.s))\n",
    "\n",
    "# * S matrix (sigma)\n",
    "# print(np.shape(lsi_model.projection.s))\n",
    "# lsi_model.projection.s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "right singular vectors -> document-to-topic matrix (Não é diretamente calculado e armazenado pois pode ser muito grande devido a quantidade de documentos -> num_topic x documents)\n",
    "\n",
    "Será o documento armazenado e utilizado para fazer as queries de similaridade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57, 56)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 8.65639864e-02,  1.36961764e-02, -9.24501293e-04, ...,\n",
       "        -1.26261545e-03,  4.68753438e-03, -7.78660085e-03],\n",
       "       [ 2.10585009e-01, -7.49511223e-02,  3.56860094e-01, ...,\n",
       "         3.33012310e-02,  2.56425229e-02,  2.85042882e-02],\n",
       "       [ 1.48849877e-01, -5.66447424e-02,  2.52708268e-01, ...,\n",
       "         1.60413206e-03, -7.43994227e-03, -5.22567216e-03],\n",
       "       ...,\n",
       "       [ 5.10636334e-02,  2.65972771e-02,  7.62101030e-03, ...,\n",
       "         8.15846110e-03,  5.07323645e-03, -5.00949213e-04],\n",
       "       [ 7.78321770e-02,  3.89569428e-01,  1.00091197e-02, ...,\n",
       "        -1.33719254e-03,  2.87992360e-03,  4.60007103e-03],\n",
       "       [ 1.33661207e-01,  5.82024790e-01,  9.95294558e-03, ...,\n",
       "         9.30639697e-03, -8.30797207e-03, -3.62127897e-03]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V_matrix = gensim.matutils.corpus2dense(lsi_model[tfidf_model[corpus]], len(lsi_model.projection.s)).T / lsi_model.projection.s\n",
    "print(np.shape(V_matrix))\n",
    "# * V or V^T matrix\n",
    "# * representado por lsi_model[x]\n",
    "V_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando, então, o corpus já processado pelo tf_idf e também a matrix V de LSI em um arquivo texto do tipo Matrix Market format, que permite que a matriz seja guardado em um arquivo texto, mas também pode ser utilizado para cálculos. (o método Serialize guardas os indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "gensim.corpora.MmCorpus.serialize('tfidf_model_mm', tfidf_model[corpus])\n",
    "gensim.corpora.MmCorpus.serialize('lsi_model_mm', lsi_model[tfidf_model[corpus]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abrindo as matrizes salvas nos arquivos textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MmCorpus(57 documents, 1869 features, 3980 non-zero entries)\n",
      "MmCorpus(57 documents, 56 features, 3192 non-zero entries)\n"
     ]
    }
   ],
   "source": [
    "tfidf_corpus = gensim.corpora.MmCorpus('tfidf_model_mm')\n",
    "lsi_corpus = gensim.corpora.MmCorpus('lsi_model_mm')\n",
    "\n",
    "# * features of td-idf matrix are the different words\n",
    "print(tfidf_corpus)\n",
    "\n",
    "# * features of LSI model are the latent topics discovered\n",
    "print(lsi_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buscas de Similaridade Semântica utilizando o método Matrix similarity do gensim, o qual computa o \"cosine similarity\".\n",
    "\n",
    "Se forem buscados termos que não foram adicionados ao dicionário id2wordDict, não há como mapear esse documento\n",
    "\n",
    "O parâmetro num_best define quantos dos documentos mais proximos será buscado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.similarities.docsim import MatrixSimilarity\n",
    "\n",
    "cosineSimilarity = MatrixSimilarity(lsi_corpus, num_features = lsi_corpus.num_terms, num_best=8)\n",
    "\n",
    "def search_similarity_query(search_document):\n",
    "\n",
    "    # * preprocessing and processing until becomes a matrix of type term_to_topic (V)\n",
    "    doc = preprocess(search_document)\n",
    "    query_bow = id2wordDict.doc2bow(doc)\n",
    "    query_tfidf = tfidf_model[query_bow]\n",
    "    query_lsi = lsi_model[query_tfidf]\n",
    "\n",
    "    # * cossine similarity between the vector of the new document vs all other vectors of documents\n",
    "    # * returns a list of tuples (id of compared document, similarity)\n",
    "    ranking = cosineSimilarity[query_lsi]\n",
    "\n",
    "    ranking.sort(key=lambda unit: unit[1], reverse= True)\n",
    "    result = []\n",
    "\n",
    "    for subject in ranking:\n",
    "\n",
    "        result.append (\n",
    "            {\n",
    "                'Relevancia': round((subject[1] * 100),6),\n",
    "                'Código da Matéria': subjects_df['codigo'][subject[0]],\n",
    "                'Nome da matéria': subjects_df['nome'][subject[0]]\n",
    "            }\n",
    "\n",
    "        )\n",
    "    \n",
    "    output = pd.DataFrame(result, columns=['Relevancia','Código da Matéria','Nome da matéria'])\n",
    "    \n",
    "    return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando documentos no formato de str, pode-se realizar buscas de similaridade semântica entre as matérias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['eletromagnetismo']\n"
     ]
    }
   ],
   "source": [
    "search_similarity_query(\"eletromagnético\")\n",
    "print(preprocess(\"eletromagnético\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi-queries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2211, 9)\n"
     ]
    }
   ],
   "source": [
    "print( mechatronics_df.shape )\n",
    "\n",
    "query_full_text = \"\"\n",
    "\n",
    "for i in range(2211):\n",
    "    text = mechatronics_df.iloc[i, 8] + ' ' + mechatronics_df.iloc[i, 7]\n",
    "    # print(f'conteúdo buscado: {mechatronics_df.iloc[i, 8]},\\nárea do conhecimento: {mechatronics_df.iloc[i, 7]}')\n",
    "    # print(f'texto buscado depois de preprocessado: {preprocess(text)}')\n",
    "    # print( search_similarity_query(text), end='\\n\\n')\n",
    "    query_full_text += \"Index: \" + str(i) + '\\n'\n",
    "    query_full_text += \"Conteúdo buscado: \" + mechatronics_df.iloc[i, 8] + '\\n'\n",
    "    query_full_text += \"área do conhecimento: \" + mechatronics_df.iloc[i, 7] + '\\n'\n",
    "    query_full_text += \"Texto buscado depois de preprocessado: \" + str(preprocess(text)) + '\\n'\n",
    "    query_full_text += search_similarity_query(text).to_string() + \"\\n\\n\"\n",
    "\n",
    "with open(\"mechatronics_requirements_query.txt\", 'w') as f:\n",
    "    f.write(query_full_text)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ae7890921ac3c17143ff000ac7152addc6614e2051824da39aa37dab63d26d82"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
